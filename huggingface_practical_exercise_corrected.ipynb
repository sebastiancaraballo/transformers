{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ó Hugging Face LLM Course Practical Exercise\n",
        "\n",
        "## üìù Exercise: Train and Share Your First Transformer\n",
        "\n",
        "### üéØ Goal\n",
        "By completing this exercise, you will apply the concepts from Chapters 1‚Äì4 of the Hugging Face LLM course:\n",
        "\n",
        "- Use a pretrained Transformer model for text classification\n",
        "- Fine-tune the model on a small dataset\n",
        "- Evaluate its performance\n",
        "- Share the model publicly on the Hugging Face Hub\n",
        "\n",
        "---\n",
        "\n",
        "### üìö Chapters Covered\n",
        "- **Chapter 1-2**: Using pretrained models with pipelines\n",
        "- **Chapter 3**: Fine-tuning models on custom datasets\n",
        "- **Chapter 4**: Sharing models on the Hugging Face Hub\n",
        "\n",
        "---\n",
        "\n",
        "### üöÄ Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Install Required Libraries\n",
        "\n",
        "First, let's install all the necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install transformers datasets torch evaluate accelerate huggingface_hub ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîπ 1. Load a Pretrained Model (Chapter 1‚Äì2)\n",
        "\n",
        "Let's start by using the Hugging Face `pipeline` API to load a sentiment analysis model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use mps:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Sentiment analysis pipeline loaded successfully!\n",
            "Model: distilbert-base-uncased-finetuned-sst-2-english\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# Load the sentiment analysis pipeline\n",
        "sentiment_pipeline = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Sentiment analysis pipeline loaded successfully!\")\n",
        "print(f\"Model: {sentiment_pipeline.model.name_or_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test the Pretrained Model\n",
        "\n",
        "Now let's test our model with some example sentences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Testing the pretrained model:\n",
            "==================================================\n",
            "1. Sentence: I love this movie, it's absolutely fantastic!\n",
            "   Prediction: POSITIVE (Confidence: 1.000)\n",
            "\n",
            "2. Sentence: This is the worst experience I've ever had.\n",
            "   Prediction: NEGATIVE (Confidence: 1.000)\n",
            "\n",
            "3. Sentence: The food was okay, nothing special.\n",
            "   Prediction: NEGATIVE (Confidence: 0.983)\n",
            "\n",
            "4. Sentence: I'm feeling great about this project!\n",
            "   Prediction: POSITIVE (Confidence: 1.000)\n",
            "\n",
            "5. Sentence: This product is terrible, don't buy it.\n",
            "   Prediction: NEGATIVE (Confidence: 1.000)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test sentences\n",
        "test_sentences = [\n",
        "    \"I love this movie, it's absolutely fantastic!\",\n",
        "    \"This is the worst experience I've ever had.\",\n",
        "    \"The food was okay, nothing special.\",\n",
        "    \"I'm feeling great about this project!\",\n",
        "    \"This product is terrible, don't buy it.\"\n",
        "]\n",
        "\n",
        "print(\"üîç Testing the pretrained model:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for i, sentence in enumerate(test_sentences, 1):\n",
        "    result = sentiment_pipeline(sentence)\n",
        "    label = result[0]['label']\n",
        "    score = result[0]['score']\n",
        "    \n",
        "    print(f\"{i}. Sentence: {sentence}\")\n",
        "    print(f\"   Prediction: {label} (Confidence: {score:.3f})\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîπ 2. Fine-tune the Model on a Dataset (Chapter 3)\n",
        "\n",
        "Now let's fine-tune our model on the IMDb dataset. We'll use a **balanced random subset** to ensure proper training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìö Loading IMDb dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üé≤ Creating balanced random subset...\n",
            "‚úÖ Training set: 1000 samples\n",
            "‚úÖ Test set: 200 samples\n",
            "‚úÖ Dataset features: {'text': Value('string'), 'label': ClassLabel(names=['neg', 'pos'])}\n",
            "‚úÖ Training set balance:\n",
            "   - Label 0: 500 samples (50.0%)\n",
            "   - Label 1: 500 samples (50.0%)\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Load IMDb dataset\n",
        "print(\"üìö Loading IMDb dataset...\")\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# Create a BALANCED random subset for proper training\n",
        "print(\"üé≤ Creating balanced random subset...\")\n",
        "random.seed(42)  # For reproducibility\n",
        "\n",
        "# Get random indices for balanced sampling\n",
        "all_indices = list(range(len(dataset[\"train\"])))\n",
        "random.shuffle(all_indices)\n",
        "\n",
        "# Take 500 negative and 500 positive samples\n",
        "neg_indices = [i for i in all_indices if dataset[\"train\"][i][\"label\"] == 0][:500]\n",
        "pos_indices = [i for i in all_indices if dataset[\"train\"][i][\"label\"] == 1][:500]\n",
        "\n",
        "balanced_indices = neg_indices + pos_indices\n",
        "random.shuffle(balanced_indices)  # Shuffle again for training\n",
        "\n",
        "train_dataset = dataset[\"train\"].select(balanced_indices)\n",
        "test_dataset = dataset[\"test\"].select(range(200))\n",
        "\n",
        "print(f\"‚úÖ Training set: {len(train_dataset)} samples\")\n",
        "print(f\"‚úÖ Test set: {len(test_dataset)} samples\")\n",
        "print(f\"‚úÖ Dataset features: {train_dataset.features}\")\n",
        "\n",
        "# Verify balance\n",
        "train_labels = train_dataset[\"label\"]\n",
        "unique, counts = np.unique(train_labels, return_counts=True)\n",
        "print(f\"‚úÖ Training set balance:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    percentage = (count / len(train_labels)) * 100\n",
        "    print(f\"   - Label {label}: {count} samples ({percentage:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Loading tokenizer and model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Tokenizer: distilbert-base-uncased\n",
            "‚úÖ Model: distilbert-base-uncased\n",
            "‚úÖ Number of labels: 2\n",
            "‚úÖ Label mapping: {0: 'neg', 1: 'pos'}\n"
          ]
        }
      ],
      "source": [
        "# Load tokenizer and model\n",
        "print(\"üîß Loading tokenizer and model...\")\n",
        "\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# FIXED: Use correct label mapping for IMDb dataset\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name, \n",
        "    num_labels=2,\n",
        "    id2label={0: \"neg\", 1: \"pos\"},  # IMDb uses 'neg' and 'pos'\n",
        "    label2id={\"neg\": 0, \"pos\": 1}   # IMDb uses 'neg' and 'pos'\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Tokenizer: {tokenizer.name_or_path}\")\n",
        "print(f\"‚úÖ Model: {model.name_or_path}\")\n",
        "print(f\"‚úÖ Number of labels: {model.num_labels}\")\n",
        "print(f\"‚úÖ Label mapping: {model.config.id2label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî§ Tokenizing datasets...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e235c4a2e1d4e71a0cc74b91860917d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Tokenization completed!\n"
          ]
        }
      ],
      "source": [
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"], \n",
        "        padding=\"max_length\", \n",
        "        truncation=True, \n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "# Tokenize datasets\n",
        "print(\"üî§ Tokenizing datasets...\")\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "print(\"‚úÖ Tokenization completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sebastiancaraballo/.pyenv/versions/3.10.0/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/var/folders/jh/w0pm_lpx0h39rjg359_zydhm0000gn/T/ipykernel_33886/119086075.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Starting training...\n",
            "Training arguments: TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=epoch,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=epoch,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=./results/runs/Aug14_17-22-26_192.168.1.5,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=./results,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=./results,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.01,\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Load accuracy metric\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "# Define compute_metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,  # Increased epochs for better learning\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,  # We'll do this manually later\n",
        "    report_to=None,  # Disable wandb logging\n",
        ")\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"üöÄ Starting training...\")\n",
        "print(f\"Training arguments: {training_args}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî• Training in progress...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61b7a1898496424185287926b5b2df1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/375 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7217a5f62f0741298681391ab131c99b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.34465354681015015, 'eval_accuracy': 0.855, 'eval_runtime': 10.0093, 'eval_samples_per_second': 19.982, 'eval_steps_per_second': 2.498, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a566ca5b18b949cdab8c6e7e32adf1af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5784940123558044, 'eval_accuracy': 0.84, 'eval_runtime': 9.9742, 'eval_samples_per_second': 20.052, 'eval_steps_per_second': 2.506, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83c228c960304d23ad1ef997651f0773",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5707761645317078, 'eval_accuracy': 0.845, 'eval_runtime': 9.6925, 'eval_samples_per_second': 20.634, 'eval_steps_per_second': 2.579, 'epoch': 3.0}\n",
            "{'train_runtime': 524.0186, 'train_samples_per_second': 5.725, 'train_steps_per_second': 0.716, 'train_loss': 0.2763664957682292, 'epoch': 3.0}\n",
            "‚úÖ Training completed!\n",
            "Best model saved at: ./results/checkpoint-125\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "print(\"üî• Training in progress...\")\n",
        "trainer.train()\n",
        "\n",
        "print(\"‚úÖ Training completed!\")\n",
        "print(f\"Best model saved at: {trainer.state.best_model_checkpoint}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîπ 3. Evaluate the Model\n",
        "\n",
        "Let's evaluate our fine-tuned model and test it with some examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Evaluating the fine-tuned model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "001f1328d2bc410f8cdb34ee35496f97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìà Evaluation Results:\n",
            "==============================\n",
            "eval_loss: 0.3447\n",
            "eval_accuracy: 0.8550\n",
            "eval_runtime: 10.0009\n",
            "eval_samples_per_second: 19.9980\n",
            "eval_steps_per_second: 2.5000\n",
            "epoch: 3.0000\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "print(\"üìä Evaluating the fine-tuned model...\")\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "print(\"\\nüìà Evaluation Results:\")\n",
        "print(\"=\" * 30)\n",
        "for key, value in eval_results.items():\n",
        "    print(f\"{key}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use mps:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üß™ Testing the fine-tuned model:\n",
            "========================================\n",
            "1. Sentence: This movie was absolutely incredible!\n",
            "   Prediction: pos (Confidence: 0.916)\n",
            "\n",
            "2. Sentence: I hated every minute of this film.\n",
            "   Prediction: neg (Confidence: 0.837)\n",
            "\n",
            "3. Sentence: The acting was superb and the story was engaging.\n",
            "   Prediction: pos (Confidence: 0.934)\n",
            "\n",
            "4. Sentence: This is the worst movie I've ever seen.\n",
            "   Prediction: neg (Confidence: 0.873)\n",
            "\n",
            "5. Sentence: I really enjoyed this film, highly recommended!\n",
            "   Prediction: pos (Confidence: 0.943)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test the fine-tuned model with some examples\n",
        "print(\"\\nüß™ Testing the fine-tuned model:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Create a pipeline with our fine-tuned model\n",
        "fine_tuned_pipeline = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=trainer.model,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Test sentences\n",
        "test_sentences = [\n",
        "    \"This movie was absolutely incredible!\",\n",
        "    \"I hated every minute of this film.\",\n",
        "    \"The acting was superb and the story was engaging.\",\n",
        "    \"This is the worst movie I've ever seen.\",\n",
        "    \"I really enjoyed this film, highly recommended!\"\n",
        "]\n",
        "\n",
        "for i, sentence in enumerate(test_sentences, 1):\n",
        "    result = fine_tuned_pipeline(sentence)\n",
        "    label = result[0]['label']\n",
        "    score = result[0]['score']\n",
        "    \n",
        "    print(f\"{i}. Sentence: {sentence}\")\n",
        "    print(f\"   Prediction: {label} (Confidence: {score:.3f})\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîπ 4. Share the Model on the Hub (Chapter 4)\n",
        "\n",
        "Now let's share our fine-tuned model on the Hugging Face Hub!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First, let's login to Hugging Face\n",
        "print(\"üîê Logging in to Hugging Face Hub...\")\n",
        "print(\"Please run 'huggingface-cli login' in your terminal first if you haven't already.\")\n",
        "print(\"Or use the notebook_login() function below:\")\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# Uncomment the line below to login from the notebook\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Saving model and tokenizer locally...\n",
            "‚úÖ Model and tokenizer saved to: ./my-fine-tuned-sentiment-model\n"
          ]
        }
      ],
      "source": [
        "# Save the model and tokenizer locally first\n",
        "print(\"üíæ Saving model and tokenizer locally...\")\n",
        "\n",
        "output_dir = \"./my-fine-tuned-sentiment-model\"\n",
        "trainer.save_model(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"‚úÖ Model and tokenizer saved to: {output_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Pushing model to Hugging Face Hub...\n",
            "Repository name: sebastiancaraballo/imdb-sentiment-finetuned\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "916e725f393048d9aa2c7d9583686dcc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model successfully pushed to: https://huggingface.co/sebastiancaraballo/imdb-sentiment-finetuned\n"
          ]
        }
      ],
      "source": [
        "# Push to Hub\n",
        "print(\"üöÄ Pushing model to Hugging Face Hub...\")\n",
        "\n",
        "# You can customize this repository name\n",
        "repo_name = \"sebastiancaraballo/imdb-sentiment-finetuned\"  # Change this!\n",
        "\n",
        "print(f\"Repository name: {repo_name}\")\n",
        "\n",
        "# Push the model\n",
        "model.push_to_hub(repo_name)\n",
        "tokenizer.push_to_hub(repo_name)\n",
        "\n",
        "print(f\"‚úÖ Model successfully pushed to: https://huggingface.co/{repo_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Congratulations!\n",
        "\n",
        "You've successfully completed the Hugging Face LLM Course practical exercise!\n",
        "\n",
        "### üìã What You've Accomplished:\n",
        "\n",
        "‚úÖ **Chapter 1-2**: Loaded and used a pretrained sentiment analysis model\n",
        "‚úÖ **Chapter 3**: Fine-tuned the model on the IMDb dataset with proper balanced sampling\n",
        "‚úÖ **Chapter 4**: Prepared to share your model on the Hugging Face Hub\n",
        "\n",
        "### üöÄ Next Steps:\n",
        "\n",
        "1. **Set your repository name** in the cell above\n",
        "2. **Run the push_to_hub commands** to share your model\n",
        "3. **Visit your model page** on huggingface.co\n",
        "4. **Test your model** using the inference widget\n",
        "\n",
        "### üîó Useful Links:\n",
        "- [Hugging Face Hub](https://huggingface.co/)\n",
        "- [Model Hub Documentation](https://huggingface.co/docs/hub/index)\n",
        "- [Transformers Documentation](https://huggingface.co/docs/transformers/)\n",
        "\n",
        "### üí° Tips for Future Projects:\n",
        "- **Always verify dataset balance** before training\n",
        "- **Use random sampling** instead of taking the first N samples\n",
        "- **Ensure label mapping matches** your dataset\n",
        "- **Monitor training metrics** to detect issues early\n",
        "- **Experiment with different model architectures**\n",
        "- **Try different datasets and tasks**\n",
        "- **Use larger training sets for better performance**\n",
        "- **Explore hyperparameter tuning**\n",
        "- **Consider using model evaluation metrics beyond accuracy**\n",
        "\n",
        "### üêõ Common Issues and Solutions:\n",
        "\n",
        "1. **All predictions are the same class**: Check dataset balance and label mapping\n",
        "2. **100% accuracy**: Usually indicates overfitting or dataset issues\n",
        "3. **Poor performance**: Try more training data or different hyperparameters\n",
        "4. **Label mismatch**: Ensure your model's label mapping matches the dataset\n",
        "\n",
        "Happy modeling! üéØ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
